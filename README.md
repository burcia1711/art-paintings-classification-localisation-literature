# Computer Vision for Object Classification and Localisation in Art Paintings
## Introduction

Applying computer vision (CV) and machine learning to art paintings enables automatic identification of objects and their locations within artworks. However, models trained on photographs often struggle with paintings – a phenomenon known as the cross-depiction problem [[1]](https://github.com/burcia1711/art-paintings-classification-localisation-literature/blob/main/2016%20-%20Detecting%20People%20in%20Artwork%20with%20CNNs.pdf). Paintings differ from photos in both form (many styles and abstract depictions) and content (symbolic or imaginary objects not seen in everyday life), and large annotated datasets of art are scarce [[2]](https://github.com/burcia1711/art-paintings-classification-localisation-literature/blob/main/2022%20-%20DEArt%20Dataset%20of%20European%20Art.pdf). Despite these challenges, recent research has adapted deep learning methods (e.g. convolutional neural networks and transformers) through transfer learning, domain adaptation, and specialized techniques to detect and localize objects in paintings. This report surveys key academic studies, covering general-purpose approaches and style-specific findings (from Renaissance realism to Cubist abstraction). We highlight important datasets, state-of-the-art methodologies (architectures and transfer strategies), known challenges (stylistic variance, limited labels), and practical applications in art curation, search, and restoration.

## Datasets and Challenges in Art Object Detection

Building robust object detectors for art requires annotated datasets of paintings. Several dedicated datasets have emerged:

- PeopleArt: 4,821 images across 43 depiction styles (41 art styles from WikiArt, plus photos and cartoons) with people manually annotated [[1]](https://github.com/burcia1711/art-paintings-classification-localisation-literature/blob/main/2016%20-%20Detecting%20People%20in%20Artwork%20with%20CNNs.pdf). This dataset was introduced to tackle cross-depiction person detection. Models fine-tuned on [PeopleArt](https://github.com/BathVisArtData/PeopleArt) showed improved performance but still achieved under 60% average precision, underscoring the difficulty of detecting objects in art.

- IconArt: ~5,955 WikiCommons paintings (4,458 with annotations) labelled for 7 object classes [[3]](https://github.com/burcia1711/art-paintings-classification-localisation-literature/blob/main/2018%20-%20Weakly%20Supervised%20Object%20Detection%20in%20Artworks.pdf). Uniquely, IconArt includes iconographic classes absent in photographs (e.g. “Jesus Child” or “Saint Sebastian”) and was annotated only at image-level for a weakly supervised detection task. This allows learning without bounding boxes, though only a few classes are covered.

- PrintArt: A smaller dataset of 988 artwork images with 8 object categories [[4]](https://github.com/burcia1711/art-paintings-classification-localisation-literature/blob/main/2012%20-%20Artistic%20Image%20Classification%20An%20Analysis%20on%20the%20PRINTART%20Database.pdf). One of the early datasets, it has a limited size and classes.

- DEArt: The largest to date, with over 15,000 European paintings (12th–18th century) annotated for 69 object classes and ~12 human pose categories 
[[2]](https://github.com/burcia1711/art-paintings-classification-localisation-literature/blob/main/2022%20-%20DEArt%20Dataset%20of%20European%20Art.pdf). Over 50 classes are specific to cultural heritage (e.g. angels, mythological creatures, historical items) not found in typical photo datasets. DEArt provides exhaustive bounding boxes and even pose labels for people, enabling both object detection and pose classification in art

Beyond these, other art datasets exist (SemArt, OmniArt, WikiArt, The Met’s Open Access set), but those focus on classification or captioning and lack bounding-box annotations. The scarcity of detection-labelled data is a core challenge, even DEArt’s 15k images are small by deep learning standards. Paintings also exhibit extreme style diversity (from realistic Renaissance to abstract modernism), causing models to misinterpret artistic depictions. For example, a lion depicted in a medieval tapestry or a cubist portrait can appear quite different from a photo. Artworks frequently contain symbolic or historical objects (crowns, mythological figures, etc.) and scenes outside everyday experience. This stylistic variance and unique iconography, combined with the limited data, lead to significantly lower detection accuracy when applying off-the-shelf models to art. Researchers have noted that only the first few layers of a photo-trained CNN carry over effectively to paintings, with deeper features overfitting to photographic texture. In sum, the domain gap between photos and paintings, sometimes called the cross-depiction or cross-domain problem, is the central obstacle to object classification/localisation in art.

## Methodologies and Key Research

Researchers have explored a variety of strategies to bridge the gap between natural images and artwork for object detection:

### Transfer Learning on Pre-Trained CNNs

A common approach is to fine-tune powerful object detectors (e.g. Faster R-CNN or YOLO) that were pre-trained on large photo datasets like COCO. Westlake et al. (2016) fine-tuned a Fast R-CNN on the PeopleArt dataset for person detection [[1]](https://github.com/burcia1711/art-paintings-classification-localisation-literature/blob/main/2016%20-%20Detecting%20People%20in%20Artwork%20with%20CNNs.pdf). This achieved state-of-the-art results on PeopleArt, confirming that transfer learning is beneficial, but performance plateaued below 60% AP, highlighting remaining gaps. They observed that “training CNNs on photos results in overfitting for photos”, recommending retraining most layers when moving to art. Recent work with DEArt similarly showed that a Faster R-CNN (ResNet-152) pre-trained on MS COCO can reach ~31.2% AP on the 69 art classes, about 87% of the accuracy achieved on natural images [[2]](https://github.com/burcia1711/art-paintings-classification-localisation-literature/blob/main/2022%20-%20DEArt%20Dataset%20of%20European%20Art.pdf). This is a notable improvement, indicating that with sufficient art-specific data and transfer learning, detectors can approach photo-level performance. Modern CNN backbones (ResNet, EfficientNet) and transformer-based detectors (DETR, Vision Transformers) have also been applied in research, generally starting from weights learned on ImageNet or COCO and then adapted to paintings. The key is leveraging learned low-level features (edges, shapes) while fine-tuning higher layers to interpret painterly textures and distortions.

Open-vocabulary and multi-modal models are a very recent development: models like GLIP (Grounded Language-Image Pre-training) integrate language descriptions into detection. GLIP was shown to generalise surprisingly well to art without task-specific training, for example, in one study, it correctly identified all depictions of a bull in Picasso’s progressively abstract “Le Taureau” lithograph series, whereas a 2015-era CNN detected only the most realistic instances. This suggests large-scale vision-language pretraining (as in CLIP/GLIP) can significantly improve cross-style object recognition, likely by learning more robust shape and context cues rather than texture alone [[5]](https://github.com/burcia1711/art-paintings-classification-localisation-literature/blob/main/2024%20-%20Algorithmic%20Ways%20of%20Seeing-%20Using%20Object%20Detection%20to%20Facilitate%20Art%20Exploration.pdf).

### Domain Adaptation and Style Transfer

Another line of research explicitly tackles the style gap through domain adaptation. Style transfer augmentation has proven effective: Kadish et al. (2021) generated a synthetic training set by applying AdaIN style transfers to 61,360 COCO images, re-stylising them to look like paintings [[2]](https://github.com/burcia1711/art-paintings-classification-localisation-literature/blob/main/2022%20-%20DEArt%20Dataset%20of%20European%20Art.pdf). By fine-tuning Faster R-CNN on these stylised images (without using any real paintings in training), they achieved a “significant improvement on the state of the art” for detecting people in art. Essentially, this approach injects painterly textures while preserving content, teaching the model to focus on shape and ignore texture cues [[6]](https://github.com/burcia1711/art-paintings-classification-localisation-literature/blob/main/2021%20-%20Improving%20Object%20Detection%20in%20Art%20Images%20Using%20Only%20Style%20Transfer.pdf). Other works have explored adversarial domain adaptation: for example, Bekkouch et al. (2021) used a GAN-based feature alignment to recognise medieval musical instruments across drawings and photos [[7]](https://github.com/burcia1711/art-paintings-classification-localisation-literature/blob/main/2023%20-%20A%20comprehensive%20survey%20on%20object%20detection%20in%20Visual%20Art%3A%20taxonomy%20and%20challenge.pdf). Such approaches try to make the model’s internal representations invariant to whether an image is a photo or a painting, often by adding a domain classifier loss or using generated artworks for training. These adaptation techniques address the observation that standard CNNs are overly biased to texture; by forcing a focus on shape/content, they mitigate errors on highly stylised inputs.

### Weakly Supervised and Few-Shot Detection

Because obtaining detailed annotations for art is labour-intensive, researchers have looked at weakly supervised learning, using image-level labels (what objects are present) to train detectors without bounding boxes. Gonthier et al. (2018) introduced a Multiple-Instance Learning approach to detect iconographic elements in paintings using only painting-level annotations [[3]](https://github.com/burcia1711/art-paintings-classification-localisation-literature/blob/main/2018%20-%20Weakly%20Supervised%20Object%20Detection%20in%20Artworks.pdf). Despite lacking ground-truth boxes, their method achieved only mildly lower accuracy than fully-supervised models. They demonstrated automatic localisation of subjects like “Madonna and Child” across Renaissance paintings, and published the IconArt dataset to facilitate further work. Recent advances also consider few-shot learning to accommodate novel classes with minimal labelling. For instance, Bell et al. (2022) propose a one-shot object detection framework for art, aimed at letting art historians define a new object category by providing a single example image [[8]](https://github.com/burcia1711/art-paintings-classification-localisation-literature/blob/main/2022%20-%20One-Shot%20Object%20Detection%20in%20Heterogeneous%20Artwork%20Datasets.pdf). Their system uses a specialized feature extractor that compares patches (the query object) against a target painting, along with context augmentation and contrastive learning to improve robustness. Testing on Christian iconography and the IconArt dataset, they achieved notable mAP improvements (e.g. +3–6% mAP) for unseen categories by leveraging context and relational cues. Such techniques are valuable for the long tail of art objects, where new or rare categories (mythological creatures, specific symbols) might not appear in training data. By reducing the need for exhaustive annotation, weak/few-shot methods make it feasible to scale object detection to the diversity of the art world.

### Style-Specific Considerations

Some studies have focused on particular art styles or subjects to understand style-specific performance. Cubist and abstract art pose extreme challenges due to distorted forms. Ginosar et al. (2014) demonstrated that a CNN fine-tuned on just 218 Picasso paintings (a subset of PeopleArt) could detect people in Picasso’s Cubist works [[2]](https://github.com/burcia1711/art-paintings-classification-localisation-literature/blob/main/2022%20-%20DEArt%20Dataset%20of%20European%20Art.pdf). This was one of the earliest proofs that deep nets can “learn” an abstract depiction style when trained on curated data from that style. However, success varies; models struggle with truly abstract art (e.g. non-representational Abstract Expressionism) where objects are heavily stylised or hidden. In such cases, combining visual detection with metadata or titles may be necessary, as even humans may struggle to recognise objects without context. Style-specific data augmentation can help (e.g. training on line drawings for abstract sketches, or using style-specific filters). There is also interest in iconography-specific models for styles like medieval or Renaissance art, where certain motifs (saints, heraldry, etc.) recur. The DEArt dataset explicitly expanded the label space to include such culturally significant classes (e.g. “angel” separate from generic “person”) because recognising those is crucial to understanding historical artworks [[2]](https://github.com/burcia1711/art-paintings-classification-localisation-literature/blob/main/2022%20-%20DEArt%20Dataset%20of%20European%20Art.pdf). In practice, a general model might detect a human figure. Still, a specialised model or post-processing is needed to decide if that figure is, say, St. George or a king, based on attributes and context. This borders on image interpretation and often requires attribute classification or even a few-shot recognition of specific iconographic symbols.

Handling varied scales and details is another consideration: classical paintings can be very large, with tiny but important objects (small faces in a crowd, distant animals, etc.). Techniques like Slicing Aided Hyper Inference (SAHI) have been applied to art images to improve the detection of small objects by analysing image patches at high resolution [[9]](https://github.com/burcia1711/art-paintings-classification-localisation-literature/blob/main/2018%20-%20Deep%20learning%20for%20object%20detection%20in%20fine-art%20paintings.pdf). Multi-scale training and test-time augmentations are commonly used to ensure objects of different sizes and styles can be caught. Overall, while general-purpose detectors form the backbone, fine-grained adaptations are often needed to handle the diversity across art genres – from the realistic shading of Baroque paintings to the flat colours of Pop Art or the fragmented forms of Cubism.

## Practical Applications in Art and Cultural Heritage

Robust object classification and localisation in paintings unlock many applications in the art world:

### Art Collection Indexing and Search: 
Museums and galleries digitising their collections can use object detectors to automatically tag artworks with their depicted content (people, animals, objects). This enables powerful content-based search, so curators or researchers can retrieve all works containing a certain object or theme (e.g. “find all paintings depicting a lute”) without manual cataloging [[5]](https://github.com/burcia1711/art-paintings-classification-localisation-literature/blob/main/2024%20-%20Algorithmic%20Ways%20of%20Seeing-%20Using%20Object%20Detection%20to%20Facilitate%20Art%20Exploration.pdf). For example, an experimental system called “Algorithmic Ways of Seeing” lets users browse a digital museum collection by clicking on detected objects in one painting to see similar objects across other paintings. This facilitates novel explorations of art across time periods and styles, helping users discover artworks and details they might otherwise overlook.

### Art Historical Analysis: 
Automated detection of iconographic elements enables art historians to analyse visual trends and motifs in large datasets. Researchers can quantify how often certain objects or symbols (such as specific religious icons or musical instruments) appear over time or within a particular school of art. Gonthier et al. note that such tools can “help art historians explore large digital databases” by highlighting occurrences of iconographic motifs that would be tedious to find manually [[3]](https://github.com/burcia1711/art-paintings-classification-localisation-literature/blob/main/2018%20-%20Weakly%20Supervised%20Object%20Detection%20in%20Artworks.pdf). It essentially augments the field of digital humanities for art history.

### Curation and Education: 
Curators can design exhibitions or educational content focused on particular subjects using detection results. For instance, an exhibit on “Animals in Impressionism” could be curated by automatically finding all Impressionist works containing animals. Some museums have experimented with AI-generated labels to enrich their online catalogue entries, comparing AI-detected content with traditional human metadata
[[5]](https://github.com/burcia1711/art-paintings-classification-localisation-literature/blob/main/2024%20-%20Algorithmic%20Ways%20of%20Seeing-%20Using%20Object%20Detection%20to%20Facilitate%20Art%20Exploration.pdf). This can also engage the public – the Harvard Art Museums, for example, showcased an online tool comparing AI-identified objects in paintings to expert descriptions, sparking discussion on how AI “sees” art [[5]](https://github.com/burcia1711/art-paintings-classification-localisation-literature/blob/main/2024%20-%20Algorithmic%20Ways%20of%20Seeing-%20Using%20Object%20Detection%20to%20Facilitate%20Art%20Exploration.pdf).

### Restoration and Preservation: 
Knowing the objects present in a painting can assist in restoration decisions. If a section of a painting is damaged or faded, object recognition might suggest what was originally depicted (e.g. identifying a faint shape as a missing figure of a specific saint or a historical object, based on other instances). Additionally, detecting anomalies – e.g. an object that doesn’t match the period or artist – could flag potential forgeries or past over-paintings. While this is an emerging area, researchers have used CV techniques to detect inconsistencies in paintings for authentication, and segmentation of deteriorations for conservation planning [[7]](https://github.com/burcia1711/art-paintings-classification-localisation-literature/blob/main/2023%20-%20A%20comprehensive%20survey%20on%20object%20detection%20in%20Visual%20Art%3A%20taxonomy%20and%20challenge.pdf). Object-level analysis could further guide conservators by focusing their attention on key elements of the composition during restoration.

## References
[[1] Detecting People in Artwork with CNNs](https://github.com/burcia1711/art-paintings-classification-localisation-literature/blob/main/2016%20-%20Detecting%20People%20in%20Artwork%20with%20CNNs.pdf)

[[2] DEArt: Dataset of European Art](https://github.com/burcia1711/art-paintings-classification-localisation-literature/blob/main/2022%20-%20DEArt%20Dataset%20of%20European%20Art.pdf)

[[3] Weakly Supervised Object Detection in Artworks](https://github.com/burcia1711/art-paintings-classification-localisation-literature/blob/main/2018%20-%20Weakly%20Supervised%20Object%20Detection%20in%20Artworks.pdf)

[[4] Artistic Image Classification: An Analysis on the PRINTART Database](https://github.com/burcia1711/art-paintings-classification-localisation-literature/blob/main/2012%20-%20Artistic%20Image%20Classification%20An%20Analysis%20on%20the%20PRINTART%20Database.pdf)

[[5] Algorithmic Ways of Seeing: Using Object Detection to Facilitate Art Exploration](https://github.com/burcia1711/art-paintings-classification-localisation-literature/blob/main/2024%20-%20Algorithmic%20Ways%20of%20Seeing-%20Using%20Object%20Detection%20to%20Facilitate%20Art%20Exploration.pdf)

[[6] Improving Object Detection in Art Images Using
Only Style Transfer](https://github.com/burcia1711/art-paintings-classification-localisation-literature/blob/main/2021%20-%20Improving%20Object%20Detection%20in%20Art%20Images%20Using%20Only%20Style%20Transfer.pdf)

[[7] A comprehensive survey on object detection in Visual Art:
taxonomy and challenge](https://github.com/burcia1711/art-paintings-classification-localisation-literature/blob/main/2023%20-%20A%20comprehensive%20survey%20on%20object%20detection%20in%20Visual%20Art%3A%20taxonomy%20and%20challenge.pdf)

[[8] One-Shot Object Detection in Heterogeneous Artwork Datasets](https://github.com/burcia1711/art-paintings-classification-localisation-literature/blob/main/2022%20-%20One-Shot%20Object%20Detection%20in%20Heterogeneous%20Artwork%20Datasets.pdf)

[[9] Deep learning for object detection in fine-art paintings](https://github.com/burcia1711/art-paintings-classification-localisation-literature/blob/main/2018%20-%20Deep%20learning%20for%20object%20detection%20in%20fine-art%20paintings.pdf)
