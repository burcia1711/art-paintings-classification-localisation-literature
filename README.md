# Computer Vision for Object Classification and Localisation in Art Paintings
## Introduction

Applying computer vision (CV) and machine learning to art paintings enables automatic identification of objects and their locations within artworks. However, models trained on photographs often struggle with paintings – a phenomenon known as the cross-depiction problem [[1]](https://github.com/burcia1711/art-paintings-classification-localisation-literature/blob/main/2016%20-%20Detecting%20People%20in%20Artwork%20with%20CNNs.pdf). Paintings differ from photos in both form (many styles and abstract depictions) and content (symbolic or imaginary objects not seen in everyday life), and large annotated datasets of art are scarce [[2]](https://github.com/burcia1711/art-paintings-classification-localisation-literature/blob/main/2022%20-%20DEArt%20Dataset%20of%20European%20Art.pdf). Despite these challenges, recent research has adapted deep learning methods (e.g. convolutional neural networks and transformers) through transfer learning, domain adaptation, and specialized techniques to detect and localize objects in paintings. This report surveys key academic studies, covering general-purpose approaches and style-specific findings (from Renaissance realism to Cubist abstraction). We highlight important datasets, state-of-the-art methodologies (architectures and transfer strategies), known challenges (stylistic variance, limited labels), and practical applications in art curation, search, and restoration.

## Datasets and Challenges in Art Object Detection

Building robust object detectors for art requires annotated datasets of paintings. Several dedicated datasets have emerged:

- PeopleArt: 4,821 images across 43 depiction styles (41 art styles from WikiArt, plus photos and cartoons) with people manually annotated [[1]](https://github.com/burcia1711/art-paintings-classification-localisation-literature/blob/main/2016%20-%20Detecting%20People%20in%20Artwork%20with%20CNNs.pdf). This dataset was introduced to tackle cross-depiction person detection. Models fine-tuned on [PeopleArt](https://github.com/BathVisArtData/PeopleArt) showed improved performance but still achieved under 60% average precision, underscoring the difficulty of detecting objects in art.

- IconArt: ~5,955 WikiCommons paintings (4,458 with annotations) labelled for 7 object classes [[3]](https://github.com/burcia1711/art-paintings-classification-localisation-literature/blob/main/2018%20-%20Weakly%20Supervised%20Object%20Detection%20in%20Artworks.pdf). Uniquely, IconArt includes iconographic classes absent in photographs (e.g. “Jesus Child” or “Saint Sebastian”) and was annotated only at image-level for a weakly supervised detection task. This allows learning without bounding boxes, though only a few classes are covered.

- PrintArt: A smaller dataset of 988 artwork images with 8 object categories [[4]](https://github.com/burcia1711/art-paintings-classification-localisation-literature/blob/main/2012%20-%20Artistic%20Image%20Classification%20An%20Analysis%20on%20the%20PRINTART%20Database.pdf). One of the early datasets, it has a limited size and classes.

- DEArt: The largest to date, with over 15,000 European paintings (12th–18th century) annotated for 69 object classes and ~12 human pose categories 
[[2]](https://github.com/burcia1711/art-paintings-classification-localisation-literature/blob/main/2022%20-%20DEArt%20Dataset%20of%20European%20Art.pdf). Over 50 classes are specific to cultural heritage (e.g. angels, mythological creatures, historical items) not found in typical photo datasets. DEArt provides exhaustive bounding boxes and even pose labels for people, enabling both object detection and pose classification in art

Beyond these, other art datasets exist (SemArt, OmniArt, WikiArt, The Met’s Open Access set), but those focus on classification or captioning and lack bounding-box annotations. The scarcity of detection-labelled data is a core challenge – even DEArt’s 15k images are small by deep learning standards. Paintings also exhibit extreme style diversity (from realistic Renaissance to abstract modernism), causing models to misinterpret artistic depictions. For example, a lion depicted in a medieval tapestry or a cubist portrait can appear quite different from a photo. Artworks frequently contain symbolic or historical objects (crowns, mythological figures, etc.) and scenes outside everyday experience. This stylistic variance and unique iconography, combined with the limited data, lead to significantly lower detection accuracy when applying off-the-shelf models to art. Researchers have noted that only the first few layers of a photo-trained CNN carry over effectively to paintings, with deeper features overfitting to photographic texture. In sum, the domain gap between photos and paintings – sometimes called the cross-depiction or cross-domain problem – is the central obstacle to object classification/localisation in art.

## References
- [[1] Detecting People in Artwork with CNNs](https://github.com/burcia1711/art-paintings-classification-localisation-literature/blob/main/2016%20-%20Detecting%20People%20in%20Artwork%20with%20CNNs.pdf).
- [[2] DEArt: Dataset of European Art](https://github.com/burcia1711/art-paintings-classification-localisation-literature/blob/main/2022%20-%20DEArt%20Dataset%20of%20European%20Art.pdf)
- [[3] Weakly Supervised Object Detection in Artworks](https://github.com/burcia1711/art-paintings-classification-localisation-literature/blob/main/2018%20-%20Weakly%20Supervised%20Object%20Detection%20in%20Artworks.pdf)
- [[4] Artistic Image Classification: An Analysis on the PRINTART Database](https://github.com/burcia1711/art-paintings-classification-localisation-literature/blob/main/2012%20-%20Artistic%20Image%20Classification%20An%20Analysis%20on%20the%20PRINTART%20Database.pdf)
   
